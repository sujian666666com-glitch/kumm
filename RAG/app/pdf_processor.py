import os
# æ³¨æ„ï¼šæ‚¨çš„ä»£ç ä¸­è™½ç„¶å¼•ç”¨äº† sys.path.append("..")ï¼Œ
# ä½†ä¸ºäº†ä¿æŒæ¨¡å—åŒ–ï¼Œè¿™é‡Œå‡è®¾æ‚¨ä¼šåœ¨ main.py æˆ–è¿è¡Œæ—¶æ­£ç¡®å¤„ç†å¯¼å…¥ã€‚
# è¿™é‡Œç›´æ¥ä½¿ç”¨ç›¸å¯¹å¯¼å…¥ï¼Œå‡è®¾ config æ–‡ä»¶åœ¨ app ç›®å½•ä¸‹ã€‚
from app.config import CHUNK_SIZE, CHUNK_OVERLAP 

# LangChain å¯¼å…¥ï¼šä½¿ç”¨ langchain_community å’Œ langchain_text_splitters ä¿æŒå…¼å®¹æ€§
# å¯¼å…¥ PyPDFLoader
from langchain_community.document_loaders import PyPDFLoader
# å¯¼å…¥ TextSplitter
from langchain_text_splitters import RecursiveCharacterTextSplitter
# å¯¼å…¥ Document ç±»å‹
from langchain_core.documents import Document 

# å¦‚æœæ‚¨åšæŒä½¿ç”¨ PyPDF2 è€Œä¸æ˜¯ LangChain çš„åŠ è½½å™¨ï¼Œè¯·å¯¼å…¥
# from PyPDF2 import PdfReader 
# ä½†æ¨èä½¿ç”¨ LangChain çš„åŠ è½½å™¨ï¼Œå®ƒé€šå¸¸èƒ½æ›´å¥½åœ°å¤„ç†æ–‡æ¡£ç»“æ„å’Œå…ƒæ•°æ®ã€‚

def load_and_split_pdf(pdf_paths: list[str]) -> list[str]:
    """
    åŠ è½½PDFæ–‡ä»¶ï¼Œå¹¶å°†å…¶åˆ†å‰²ä¸ºå¤šä¸ªæ–‡æœ¬å—ã€‚
    Args:
        pdf_paths: PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå¦‚ ["file1.pdf", "file2.pdf"]ï¼‰
    Returns:
        list[str]: åˆ†å‰²åçš„æ–‡æœ¬å—ï¼ˆchunkï¼‰åˆ—è¡¨
    """
    all_documents = []
    
    # 1. åŠ è½½PDFæ–‡æ¡£å¹¶æ£€æŸ¥æ–‡ä»¶
    print(f"ğŸ“„ æ­£åœ¨åŠ è½½ {len(pdf_paths)} ä¸ªPDFæ–‡ä»¶...")
    for path in pdf_paths:
        if not os.path.exists(path):
            raise FileNotFoundError(f"æ–‡ä»¶ {path} ä¸å­˜åœ¨")
        if not path.lower().endswith(".pdf"):
            raise ValueError(f"æ–‡ä»¶ {path} ä¸æ˜¯PDFæ–‡ä»¶")
        
        try:
            # ä½¿ç”¨ LangChain çš„ PyPDFLoaderï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç†æ–‡æœ¬æå–
            loader = PyPDFLoader(path)
            documents = loader.load()
            all_documents.extend(documents)
        except Exception as e:
            raise RuntimeError(f"ä½¿ç”¨ PyPDFLoader è¯»å–PDFæ–‡ä»¶å¤±è´¥ï¼š{path}ï¼Œé”™è¯¯ï¼š{e}")

    if not all_documents:
        raise ValueError("æ‰€æœ‰PDFæ–‡ä»¶ä¸­å‡æœªæå–åˆ°æœ‰æ•ˆæ–‡æ¡£")

    # 2. æ„å»ºä¸€ä¸ªé€’å½’æ–‡æœ¬åˆ†å‰²å™¨
    print(f"âœ‚ï¸ æ­£åœ¨å°†æ–‡æ¡£åˆ†å‰²ä¸ºæ–‡æœ¬å—...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE, 
        chunk_overlap=CHUNK_OVERLAP,
        length_function = len, 
        # ä¼˜åŒ–åˆ†å‰²é€»è¾‘ï¼šLangChain é»˜è®¤çš„ separators å·²ç»ä¼˜åŒ–è¿‡
        separators=["\n\n", "\n", ". ", " ", ""] 
    )
    
    # split_documents è¿”å›çš„æ˜¯ Document åˆ—è¡¨
    chunk_documents: list[Document] = text_splitter.split_documents(all_documents)
    
    # å°† Document å¯¹è±¡åˆ—è¡¨è½¬æ¢ä¸ºçº¯æ–‡æœ¬åˆ—è¡¨ (å› ä¸ºæ‚¨çš„ VectorStore.create_vector_database æ¥æ”¶çš„æ˜¯ texts)
    text_chunks: list[str] = [doc.page_content for doc in chunk_documents]
    
    return text_chunks

# --- æµ‹è¯•ä»£ç  (Test Execution) ---
if __name__ == "__main__":
    # ä¸´æ—¶é…ç½®ï¼Œä»¥ä¾¿åœ¨ç‹¬ç«‹è¿è¡Œæ—¶æµ‹è¯•
    # å‡è®¾æ‚¨çš„ app/config.py å·²ç»å°† CHUNK_SIZE å’Œ CHUNK_OVERLAP å®šä¹‰ä¸ºå¸¸é‡
    
    # ï¼ï¼ï¼è¯·æ ¹æ®æ‚¨å®é™…å­˜æ”¾çš„PDFè·¯å¾„è¿›è¡Œä¿®æ”¹ï¼ï¼ï¼
    PDF_DOCUMENTS = ["/home/jason/workdir/llm_development/langchain_v0.3/06-æ–‡æ¡£åŠ è½½å™¨/ä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸.pdf"]
    
    print("#"*20 + "å¼€å§‹å¤„ç†" + "#"*20)
    try:
        chunks = load_and_split_pdf(PDF_DOCUMENTS)
        print("#"*20 + "åˆ†å‰²åçš„chunk" + "#"*20)
        print(f"æ•°æ®ç±»å‹: {type(chunks)}, chunkæ•°é‡: {len(chunks)}")
        
        # æ‰“å°å‰5ä¸ªchunk
        for i in range(min(5, len(chunks))):
            print(f"ç¬¬{i+1}ä¸ªchunk (é•¿åº¦: {len(chunks[i])}):\n---{chunks[i][:150]}...\n")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")